{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:06.657551Z",
     "start_time": "2021-05-27T09:43:06.633567Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:06.689530Z",
     "start_time": "2021-05-27T09:43:06.657551Z"
    }
   },
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:06.721507Z",
     "start_time": "2021-05-27T09:43:06.689530Z"
    }
   },
   "outputs": [],
   "source": [
    "#read csv file\n",
    "hourly_sentiment_series = pd.read_csv(r'C:\\Users\\luc57.DESKTOP-NB5DC80\\Side Projects\\DSJ_JN\\DJ_JN\\Time Series\\hourly_users_sentiment_subset.csv',\n",
    "                                     index_col=0,\n",
    "                                     parse_dates=True, squeeze=True) #squeeze to ensure format is time-series\n",
    "print(hourly_sentiment_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:06.737496Z",
     "start_time": "2021-05-27T09:43:06.721507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check whether the index is in datetime\n",
    "print(hourly_sentiment_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:06.753484Z",
     "start_time": "2021-05-27T09:43:06.737496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preview the data to get an idea of the values and sample size\n",
    "print(hourly_sentiment_series.head())\n",
    "print()\n",
    "print(hourly_sentiment_series.tail())\n",
    "print()\n",
    "print(hourly_sentiment_series.shape) #only 24 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series models require data to be stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:06.881399Z",
     "start_time": "2021-05-27T09:43:06.753484Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "  \n",
    "# Read Images\n",
    "img = mpimg.imread(r'C:\\Users\\luc57.DESKTOP-NB5DC80\\Side Projects\\DSJ_JN\\DJ_JN\\Time Series\\stationary_data.png')\n",
    "  \n",
    "# Output Images\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:07.009314Z",
     "start_time": "2021-05-27T09:43:06.881399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data to check if stationary (constant mean and variance), \n",
    "# as many time series models require the data to be stationary\n",
    "plt.plot(hourly_sentiment_series)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is not stationary, so we need differencing (substracting the next value by the current value).\n",
    "Best not to over-difference the data because doing so can lead to inaccurate estimates.\n",
    "We also want to fil the missing values to avoid problems in the modeling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:07.185237Z",
     "start_time": "2021-05-27T09:43:07.009314Z"
    }
   },
   "outputs": [],
   "source": [
    "hourly_sentiment_series_diff1 = hourly_sentiment_series.diff().fillna(hourly_sentiment_series)\n",
    "plt.plot(hourly_sentiment_series_diff1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:07.313263Z",
     "start_time": "2021-05-27T09:43:07.185237Z"
    }
   },
   "outputs": [],
   "source": [
    "#apply the second round of differencing to make the data look more stationary.\n",
    "hourly_sentiment_series_diff2 = hourly_sentiment_series_diff1.diff().fillna(hourly_sentiment_series_diff1)\n",
    "plt.plot(hourly_sentiment_series_diff2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data now looks more stationary than the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at ACF plot and PACF plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to determine the number of AR terms and MA terms in ARMA model, or to spot seasonality trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoregressive --> forecast the next timestamp's value by regressing over the previous values\n",
    "Moving Average --> forecasts the next timestamp's value by averaging over the previous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoregressive Integrated Moving Average (ARIMA) is useful for non-stationary data and has additional seasonal differencing parameter for seasonal non-stationary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF Plot (includes 95% confidence interval band)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything outside the blue band has statistically significant correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:07.433182Z",
     "start_time": "2021-05-27T09:43:07.313263Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_acf(hourly_sentiment_series_diff2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 1 major spike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see a significant spike at lag x in the ACF, that helps determine the number of MA terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PACF Plot (95% confidence interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PACF plot is a plot of the partial correlation coefficients between the series and lags of itself. In general, the \"partial\" correlation between two variables is the amount of correlation between them which is not explained by their mutual correlations with a specified set of other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:07.546284Z",
     "start_time": "2021-05-27T09:43:07.433182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_pacf(hourly_sentiment_series_diff2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 major spikes, to determine how many AR terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see a significant spike at lag x in the PACF that helps us determine the number of AR terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure there are no gaps between datetimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:07.734014Z",
     "start_time": "2021-05-27T09:43:07.546284Z"
    }
   },
   "outputs": [],
   "source": [
    "ARMA1model_hourly_sentiment = ARIMA(hourly_sentiment_series, order=(5,2,1)).fit(transparams=False)\n",
    "#5 AR terms, 2 rounds of differencing, 1 MA term\n",
    "#transparams = True means things are stationary\n",
    "#we set to false because we have issues with the model\n",
    "\n",
    "print(ARMA1model_hourly_sentiment.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the p-value for a AR/MA coef is > 0.05, it's not significant enough to keep in the model.\n",
    "We might want to re-model using only significant terms.\n",
    "Only ma.L1.D2.users_sentiment_score is significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:53.935631Z",
     "start_time": "2021-05-27T09:43:53.911613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the next 5 hours (5 time steps ahead), \n",
    "# which is the test/holdout set\n",
    "ARMA1predict_5hourly_sentiment = ARMA1model_hourly_sentiment.predict('2/6/2019  7:00:00 PM','2/6/2019  11:00:00 PM', typ='levels')\n",
    "print('Forecast/preditions for 5 hours ahead ', ARMA1predict_5hourly_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform back the de-differenced predicted values into actual values.\n",
    "In ARIMA, this is done by specify type = 'levels'.\n",
    "However, we can also do it manually using cumsum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:43:58.018724Z",
     "start_time": "2021-05-27T09:43:57.986746Z"
    }
   },
   "outputs": [],
   "source": [
    "#diff2 back to diff1\n",
    "undiff1 = hourly_sentiment_series_diff2.cumsum().fillna(hourly_sentiment_series_diff2)\n",
    "#undiff1 back to original data\n",
    "undiff2 = undiff1.cumsum().fillna(undiff1)\n",
    "\n",
    "print(all(round(hourly_sentiment_series,6)==round(undiff2,6))) # Note: very small differences\n",
    "#round 6 places past decimal points\n",
    "print()\n",
    "print('Original values', hourly_sentiment_series.head())\n",
    "print()\n",
    "print('De-differenced values', undiff2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values look the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:44:04.165495Z",
     "start_time": "2021-05-27T09:44:04.157468Z"
    }
   },
   "outputs": [],
   "source": [
    "hourly_sentiment_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Actual vs Predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare all values with the last 5 being actual values with all values with last 5 being predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:44:07.018392Z",
     "start_time": "2021-05-27T09:44:06.994408Z"
    }
   },
   "outputs": [],
   "source": [
    "hourly_sentiment_full_actual = pd.read_csv(r'C:\\Users\\luc57.DESKTOP-NB5DC80\\Side Projects\\DSJ_JN\\DJ_JN\\Time Series\\hourly_users_sentiment_sample.csv',\n",
    "                                           index_col=0, \n",
    "                                           parse_dates=True,\n",
    "                                           squeeze=True)\n",
    "\n",
    "print('Hourly Sentiment Series: ',hourly_sentiment_series)\n",
    "print()\n",
    "print('Only last 5 actual values: ', hourly_sentiment_full_actual.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:44:09.102111Z",
     "start_time": "2021-05-27T09:44:09.094080Z"
    }
   },
   "outputs": [],
   "source": [
    "indx_row_values = hourly_sentiment_full_actual.index[19:24] \n",
    "print(indx_row_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:44:10.785823Z",
     "start_time": "2021-05-27T09:44:10.763981Z"
    }
   },
   "outputs": [],
   "source": [
    "#we can only read series values this way\n",
    "predicted_series_values = pd.Series(ARMA1predict_5hourly_sentiment, \n",
    "                                    index=['2019-02-06 19:00:00',\n",
    "                                           '2019-02-06 20:00:00',\n",
    "                                           '2019-02-06 21:00:00',\n",
    "                                           '2019-02-06 22:00:00',\n",
    "                                           '2019-02-06 23:00:00'])\n",
    "print('Predicted Series Values: ', predicted_series_values)\n",
    "print()\n",
    "hourly_sentiment_full_predicted = hourly_sentiment_series.append(predicted_series_values)\n",
    "print('Only the last five predictions: ', hourly_sentiment_full_predicted.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:44:14.233362Z",
     "start_time": "2021-05-27T09:44:14.209345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's plot actual vs predicted\n",
    "plt.plot(hourly_sentiment_full_predicted, c='orange', label='predicted')\n",
    "plt.plot(hourly_sentiment_full_actual, c='blue', label='actual')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:44:15.518654Z",
     "start_time": "2021-05-27T09:44:15.494671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the MAE to evaluate the model and see if there's \n",
    "# a big difference between actual and predicted values\n",
    "actual_values_holdout = hourly_sentiment_full_actual.iloc[19:24]\n",
    "predicted_values_holdout = hourly_sentiment_full_predicted.iloc[19:24]\n",
    "prediction_errors = []\n",
    "for i in range(len(actual_values_holdout)):\n",
    "    err = actual_values_holdout[i]-predicted_values_holdout[i]\n",
    "    prediction_errors.append(err)\n",
    "\n",
    "print('Prediction errors ', prediction_errors)\n",
    "mean_absolute_error = statistics.mean(map(abs, prediction_errors))\n",
    "print('Mean absolute error ', mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also look at RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data might not be stationary - even though looked fairly stationary to our judgement, a test would \n",
    "help better determine this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:46:20.689961Z",
     "start_time": "2021-05-27T09:46:20.665948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test (using Dickey-Fuller test) to check if 2 rounds of differencing resulted in stationary data or not\n",
    "test_results = adfuller(hourly_sentiment_series_diff2)\n",
    "\n",
    "print('p-value ', test_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If > 0.05 accept the null hypothesis, as the data is non-stationary\n",
    "If <= 0.05 reject the null hypothesis, as the data is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be done next? <br>\n",
    "Need to better transform these data: <br>\n",
    "-Stabilize the variance by applying the cube root for neg and pos values and then difference the data <br> \n",
    "-Compare models with different AR and MA terms <br>\n",
    "-This is a very small sample size of 24 timestamps, so might not have enough to spare for a holdout set  <br>\n",
    " To get more use out of your data for training, rolling over time series or timestamps at a time for different holdout sets allows for training on more timestamps; doesn't stop the model from capturing the last chunk of timestamps stored in a single holdout set <br>\n",
    "-The data only looks at 24 hours in one day <br>\n",
    " Would we start to capture more of a trend in hourly sentiment if we collected data over several days?\n",
    " How would you go about collecting more data? <br>\n",
    "-Look at model diagnostics <br>\n",
    "-Using AIC to search best model parameters <br> \n",
    "-Handle any datetime data issues <br>\n",
    "-Try other modeling techniques <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
